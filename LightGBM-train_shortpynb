{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "#train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "\n",
    "df_train = pd.read_csv('train_values_short1.csv', index_col='building_id')\n",
    "df_train_labels = pd.read_csv('train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_subset = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), \n",
    "                     LGBMClassifier(random_state=2021))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'lgbmclassifier__learning_rate': [0.1], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    'lgbmclassifier__num_leaves': [10, 20, 30, 40, 50], \n",
    "    'lgbmclassifier__num_iterations': [10, 20, 30, 40, 50, 100], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    #'lgbmclassifier__max_depth': [10, 30, 60],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dbcb6cdfe3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_values_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    848\u001b[0m                                         \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                                         \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    613\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2458\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657376602545654"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758074607885396"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbmclassifier__num_iterations': 100,\n",
       " 'lgbmclassifier__num_leaves': 50,\n",
       " 'lgbmclassifier__objective': 'regression'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df2c2bd0f67e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'lgbmclassifier__learning_rate': [0.1], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    'lgbmclassifier__num_leaves': [40, 50, 60], \n",
    "    'lgbmclassifier__num_iterations': [90, 100, 110], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    #'lgbmclassifier__max_depth': [10, 30, 60],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lgbmclassifier',\n",
       "                                        LGBMClassifier(random_state=2021))]),\n",
       "             param_grid={'lgbmclassifier__num_iterations': [90, 100, 110],\n",
       "                         'lgbmclassifier__num_leaves': [40, 50, 60],\n",
       "                         'lgbmclassifier__objective': ['regression']})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7686117858335155"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75819356001739"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbmclassifier__num_iterations': 110,\n",
       " 'lgbmclassifier__num_leaves': 60,\n",
       " 'lgbmclassifier__objective': 'regression'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'lgbmclassifier__learning_rate': [0.1], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    'lgbmclassifier__num_leaves': [50, 60, 70], \n",
    "    'lgbmclassifier__num_iterations': [100, 110, 120], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    #'lgbmclassifier__max_depth': [10, 30, 60],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lgbmclassifier',\n",
       "                                        LGBMClassifier(random_state=2021))]),\n",
       "             param_grid={'lgbmclassifier__num_iterations': [100, 110, 120],\n",
       "                         'lgbmclassifier__num_leaves': [50, 60, 70],\n",
       "                         'lgbmclassifier__objective': ['regression']})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7706148479860015"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758377752703285"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbmclassifier__num_iterations': 110,\n",
       " 'lgbmclassifier__num_leaves': 70,\n",
       " 'lgbmclassifier__objective': 'regression'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.read_csv('test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_subset = test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-3378fa5a50bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_values_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[1;32m    884\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 't'"
     ]
    }
   ],
   "source": [
    "predictions = gs.predict(test_values_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=predictions,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99355</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890251</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421793</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "300051                  3\n",
       "99355                   2\n",
       "890251                  2\n",
       "745817                  1\n",
       "421793                  3"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('submissionLGBM_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv # For dataframes\n",
    "from pandas import DataFrame # For dataframes\n",
    "from numpy import ravel # For matrices\n",
    "import matplotlib.pyplot as plt # For plotting data\n",
    "import seaborn as sns # For plotting data\n",
    "from sklearn.model_selection import train_test_split # For train/test splits\n",
    "from sklearn.neighbors import KNeighborsClassifier # The k-nearest neighbor classifier\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "from sklearn.pipeline import Pipeline # For setting up pipeline\n",
    "# Various pre-processing steps\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV # For optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'scaler':[StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
    "    #'lgbmclassifier__learning_rate': [0.1, 0.2, 0.3], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    'lgbmclassifier__num_leaves': [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200], \n",
    "    #'lgbmclassifier__num_iterations': [100, 110, 120], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    #'lgbmclassifier__max_depth': [10, 30, 60],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lgbmclassifier',\n",
       "                                        LGBMClassifier(random_state=2021))]),\n",
       "             param_grid={'lgbmclassifier__num_leaves': [10, 20, 30, 40, 50, 60,\n",
       "                                                        70, 80, 90, 100, 110,\n",
       "                                                        120, 130, 140, 150, 160,\n",
       "                                                        170, 180, 190, 200],\n",
       "                         'lgbmclassifier__objective': ['regression']})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7773377692334258"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgbmclassifier__num_leaves': 120, 'lgbmclassifier__objective': 'regression'}\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lgbmclassifier',\n",
      "                 LGBMClassifier(num_leaves=120, objective='regression',\n",
      "                                random_state=2021))])\n"
     ]
    }
   ],
   "source": [
    "# Access the best set of parameters\n",
    "best_params = gs.best_params_\n",
    "print(best_params)\n",
    "# Stores the optimum model in best_pipe\n",
    "best_pipe = gs.best_estimator_\n",
    "print(best_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_lgbmclassifier__num_leaves', 'param_lgbmclassifier__objective',\n",
      "       'params', 'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
      "       'split3_test_score', 'split4_test_score', 'split5_test_score',\n",
      "       'split6_test_score', 'split7_test_score', 'split8_test_score',\n",
      "       'split9_test_score', 'mean_test_score', 'std_test_score',\n",
      "       'rank_test_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(gs.cv_results_, orient='columns')\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lgbmclassifier__num_leaves</th>\n",
       "      <th>param_lgbmclassifier__objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.918712</td>\n",
       "      <td>1.137771</td>\n",
       "      <td>0.343283</td>\n",
       "      <td>0.037708</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 10, 'lgbmclassi...</td>\n",
       "      <td>0.751813</td>\n",
       "      <td>0.755334</td>\n",
       "      <td>0.752571</td>\n",
       "      <td>0.749962</td>\n",
       "      <td>0.759133</td>\n",
       "      <td>0.752187</td>\n",
       "      <td>0.755986</td>\n",
       "      <td>0.757099</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.754144</td>\n",
       "      <td>0.754564</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.979138</td>\n",
       "      <td>1.422715</td>\n",
       "      <td>0.471425</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>20</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 20, 'lgbmclassi...</td>\n",
       "      <td>0.755036</td>\n",
       "      <td>0.756754</td>\n",
       "      <td>0.754029</td>\n",
       "      <td>0.752379</td>\n",
       "      <td>0.760860</td>\n",
       "      <td>0.753569</td>\n",
       "      <td>0.756907</td>\n",
       "      <td>0.759478</td>\n",
       "      <td>0.758941</td>\n",
       "      <td>0.755180</td>\n",
       "      <td>0.756313</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.707010</td>\n",
       "      <td>1.361122</td>\n",
       "      <td>0.481473</td>\n",
       "      <td>0.044266</td>\n",
       "      <td>30</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 30, 'lgbmclassi...</td>\n",
       "      <td>0.755880</td>\n",
       "      <td>0.758404</td>\n",
       "      <td>0.753607</td>\n",
       "      <td>0.753185</td>\n",
       "      <td>0.762087</td>\n",
       "      <td>0.754068</td>\n",
       "      <td>0.756984</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>0.755065</td>\n",
       "      <td>0.756758</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.754056</td>\n",
       "      <td>1.732390</td>\n",
       "      <td>0.553363</td>\n",
       "      <td>0.092902</td>\n",
       "      <td>40</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 40, 'lgbmclassi...</td>\n",
       "      <td>0.755804</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.754029</td>\n",
       "      <td>0.753377</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.758135</td>\n",
       "      <td>0.760092</td>\n",
       "      <td>0.759363</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.757165</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.815114</td>\n",
       "      <td>3.135125</td>\n",
       "      <td>0.598734</td>\n",
       "      <td>0.100651</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 50, 'lgbmclassi...</td>\n",
       "      <td>0.757185</td>\n",
       "      <td>0.758058</td>\n",
       "      <td>0.755449</td>\n",
       "      <td>0.754183</td>\n",
       "      <td>0.762970</td>\n",
       "      <td>0.755257</td>\n",
       "      <td>0.758979</td>\n",
       "      <td>0.760898</td>\n",
       "      <td>0.760975</td>\n",
       "      <td>0.756792</td>\n",
       "      <td>0.758075</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.440969</td>\n",
       "      <td>3.861506</td>\n",
       "      <td>0.584454</td>\n",
       "      <td>0.061046</td>\n",
       "      <td>60</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 60, 'lgbmclassi...</td>\n",
       "      <td>0.758068</td>\n",
       "      <td>0.758250</td>\n",
       "      <td>0.754873</td>\n",
       "      <td>0.754106</td>\n",
       "      <td>0.763661</td>\n",
       "      <td>0.755257</td>\n",
       "      <td>0.759018</td>\n",
       "      <td>0.760936</td>\n",
       "      <td>0.759977</td>\n",
       "      <td>0.756332</td>\n",
       "      <td>0.758048</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.892043</td>\n",
       "      <td>3.614895</td>\n",
       "      <td>0.582489</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>70</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 70, 'lgbmclassi...</td>\n",
       "      <td>0.757492</td>\n",
       "      <td>0.758596</td>\n",
       "      <td>0.756485</td>\n",
       "      <td>0.753684</td>\n",
       "      <td>0.763124</td>\n",
       "      <td>0.754375</td>\n",
       "      <td>0.758557</td>\n",
       "      <td>0.762471</td>\n",
       "      <td>0.760169</td>\n",
       "      <td>0.757214</td>\n",
       "      <td>0.758217</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.852587</td>\n",
       "      <td>4.703184</td>\n",
       "      <td>0.584828</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>80</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 80, 'lgbmclassi...</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.758557</td>\n",
       "      <td>0.756408</td>\n",
       "      <td>0.754183</td>\n",
       "      <td>0.764006</td>\n",
       "      <td>0.755142</td>\n",
       "      <td>0.760015</td>\n",
       "      <td>0.761857</td>\n",
       "      <td>0.761781</td>\n",
       "      <td>0.756677</td>\n",
       "      <td>0.758654</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.815314</td>\n",
       "      <td>5.603614</td>\n",
       "      <td>0.609592</td>\n",
       "      <td>0.075260</td>\n",
       "      <td>90</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 90, 'lgbmclassi...</td>\n",
       "      <td>0.757799</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.755909</td>\n",
       "      <td>0.754682</td>\n",
       "      <td>0.763968</td>\n",
       "      <td>0.755833</td>\n",
       "      <td>0.760169</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.760744</td>\n",
       "      <td>0.757291</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.211909</td>\n",
       "      <td>2.210776</td>\n",
       "      <td>0.638590</td>\n",
       "      <td>0.060697</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 100, 'lgbmclass...</td>\n",
       "      <td>0.757530</td>\n",
       "      <td>0.759171</td>\n",
       "      <td>0.755756</td>\n",
       "      <td>0.754528</td>\n",
       "      <td>0.764121</td>\n",
       "      <td>0.755679</td>\n",
       "      <td>0.759286</td>\n",
       "      <td>0.763699</td>\n",
       "      <td>0.761167</td>\n",
       "      <td>0.757176</td>\n",
       "      <td>0.758811</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.479274</td>\n",
       "      <td>4.985168</td>\n",
       "      <td>0.700721</td>\n",
       "      <td>0.037794</td>\n",
       "      <td>110</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 110, 'lgbmclass...</td>\n",
       "      <td>0.757492</td>\n",
       "      <td>0.759977</td>\n",
       "      <td>0.756523</td>\n",
       "      <td>0.754490</td>\n",
       "      <td>0.763776</td>\n",
       "      <td>0.755641</td>\n",
       "      <td>0.760092</td>\n",
       "      <td>0.761896</td>\n",
       "      <td>0.760169</td>\n",
       "      <td>0.758365</td>\n",
       "      <td>0.758842</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.361399</td>\n",
       "      <td>5.366340</td>\n",
       "      <td>0.678879</td>\n",
       "      <td>0.069912</td>\n",
       "      <td>120</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 120, 'lgbmclass...</td>\n",
       "      <td>0.757761</td>\n",
       "      <td>0.760476</td>\n",
       "      <td>0.757176</td>\n",
       "      <td>0.754797</td>\n",
       "      <td>0.763431</td>\n",
       "      <td>0.757022</td>\n",
       "      <td>0.760783</td>\n",
       "      <td>0.762932</td>\n",
       "      <td>0.760629</td>\n",
       "      <td>0.757598</td>\n",
       "      <td>0.759260</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.336456</td>\n",
       "      <td>6.234517</td>\n",
       "      <td>0.714943</td>\n",
       "      <td>0.068823</td>\n",
       "      <td>130</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 130, 'lgbmclass...</td>\n",
       "      <td>0.758643</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>0.755487</td>\n",
       "      <td>0.754682</td>\n",
       "      <td>0.763008</td>\n",
       "      <td>0.758135</td>\n",
       "      <td>0.759363</td>\n",
       "      <td>0.762778</td>\n",
       "      <td>0.760130</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.758926</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31.799819</td>\n",
       "      <td>9.781685</td>\n",
       "      <td>0.694087</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>140</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 140, 'lgbmclass...</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.759018</td>\n",
       "      <td>0.756025</td>\n",
       "      <td>0.755449</td>\n",
       "      <td>0.763200</td>\n",
       "      <td>0.757828</td>\n",
       "      <td>0.760322</td>\n",
       "      <td>0.763162</td>\n",
       "      <td>0.761665</td>\n",
       "      <td>0.756639</td>\n",
       "      <td>0.759241</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.036732</td>\n",
       "      <td>6.418465</td>\n",
       "      <td>0.635857</td>\n",
       "      <td>0.053016</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 150, 'lgbmclass...</td>\n",
       "      <td>0.758490</td>\n",
       "      <td>0.759478</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>0.754528</td>\n",
       "      <td>0.763622</td>\n",
       "      <td>0.756754</td>\n",
       "      <td>0.760706</td>\n",
       "      <td>0.763431</td>\n",
       "      <td>0.761857</td>\n",
       "      <td>0.757099</td>\n",
       "      <td>0.759256</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.293388</td>\n",
       "      <td>5.402045</td>\n",
       "      <td>0.709937</td>\n",
       "      <td>0.050495</td>\n",
       "      <td>160</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 160, 'lgbmclass...</td>\n",
       "      <td>0.757991</td>\n",
       "      <td>0.758327</td>\n",
       "      <td>0.756101</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.763546</td>\n",
       "      <td>0.756523</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>0.762510</td>\n",
       "      <td>0.761051</td>\n",
       "      <td>0.758135</td>\n",
       "      <td>0.758942</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.142794</td>\n",
       "      <td>4.979184</td>\n",
       "      <td>0.792065</td>\n",
       "      <td>0.092210</td>\n",
       "      <td>170</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 170, 'lgbmclass...</td>\n",
       "      <td>0.757377</td>\n",
       "      <td>0.759785</td>\n",
       "      <td>0.757790</td>\n",
       "      <td>0.754873</td>\n",
       "      <td>0.762740</td>\n",
       "      <td>0.756178</td>\n",
       "      <td>0.760860</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.761435</td>\n",
       "      <td>0.757099</td>\n",
       "      <td>0.758965</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.852325</td>\n",
       "      <td>7.980078</td>\n",
       "      <td>0.771367</td>\n",
       "      <td>0.066224</td>\n",
       "      <td>180</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 180, 'lgbmclass...</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.758596</td>\n",
       "      <td>0.757022</td>\n",
       "      <td>0.755104</td>\n",
       "      <td>0.763392</td>\n",
       "      <td>0.756408</td>\n",
       "      <td>0.761090</td>\n",
       "      <td>0.763354</td>\n",
       "      <td>0.761627</td>\n",
       "      <td>0.757291</td>\n",
       "      <td>0.759180</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31.698663</td>\n",
       "      <td>9.119823</td>\n",
       "      <td>0.785698</td>\n",
       "      <td>0.086653</td>\n",
       "      <td>190</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 190, 'lgbmclass...</td>\n",
       "      <td>0.757032</td>\n",
       "      <td>0.759286</td>\n",
       "      <td>0.757137</td>\n",
       "      <td>0.755295</td>\n",
       "      <td>0.763699</td>\n",
       "      <td>0.757061</td>\n",
       "      <td>0.760054</td>\n",
       "      <td>0.763584</td>\n",
       "      <td>0.761282</td>\n",
       "      <td>0.757943</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.339101</td>\n",
       "      <td>8.378498</td>\n",
       "      <td>0.762081</td>\n",
       "      <td>0.075366</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__num_leaves': 200, 'lgbmclass...</td>\n",
       "      <td>0.759641</td>\n",
       "      <td>0.758519</td>\n",
       "      <td>0.755948</td>\n",
       "      <td>0.755449</td>\n",
       "      <td>0.763162</td>\n",
       "      <td>0.757176</td>\n",
       "      <td>0.760399</td>\n",
       "      <td>0.763507</td>\n",
       "      <td>0.759440</td>\n",
       "      <td>0.756332</td>\n",
       "      <td>0.758957</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       10.918712      1.137771         0.343283        0.037708   \n",
       "1       11.979138      1.422715         0.471425        0.052359   \n",
       "2       15.707010      1.361122         0.481473        0.044266   \n",
       "3       16.754056      1.732390         0.553363        0.092902   \n",
       "4       20.815114      3.135125         0.598734        0.100651   \n",
       "5       19.440969      3.861506         0.584454        0.061046   \n",
       "6       19.892043      3.614895         0.582489        0.068363   \n",
       "7       24.852587      4.703184         0.584828        0.044991   \n",
       "8       23.815314      5.603614         0.609592        0.075260   \n",
       "9       23.211909      2.210776         0.638590        0.060697   \n",
       "10      25.479274      4.985168         0.700721        0.037794   \n",
       "11      25.361399      5.366340         0.678879        0.069912   \n",
       "12      27.336456      6.234517         0.714943        0.068823   \n",
       "13      31.799819      9.781685         0.694087        0.061923   \n",
       "14      24.036732      6.418465         0.635857        0.053016   \n",
       "15      33.293388      5.402045         0.709937        0.050495   \n",
       "16      27.142794      4.979184         0.792065        0.092210   \n",
       "17      31.852325      7.980078         0.771367        0.066224   \n",
       "18      31.698663      9.119823         0.785698        0.086653   \n",
       "19      26.339101      8.378498         0.762081        0.075366   \n",
       "\n",
       "   param_lgbmclassifier__num_leaves param_lgbmclassifier__objective  \\\n",
       "0                                10                      regression   \n",
       "1                                20                      regression   \n",
       "2                                30                      regression   \n",
       "3                                40                      regression   \n",
       "4                                50                      regression   \n",
       "5                                60                      regression   \n",
       "6                                70                      regression   \n",
       "7                                80                      regression   \n",
       "8                                90                      regression   \n",
       "9                               100                      regression   \n",
       "10                              110                      regression   \n",
       "11                              120                      regression   \n",
       "12                              130                      regression   \n",
       "13                              140                      regression   \n",
       "14                              150                      regression   \n",
       "15                              160                      regression   \n",
       "16                              170                      regression   \n",
       "17                              180                      regression   \n",
       "18                              190                      regression   \n",
       "19                              200                      regression   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'lgbmclassifier__num_leaves': 10, 'lgbmclassi...           0.751813   \n",
       "1   {'lgbmclassifier__num_leaves': 20, 'lgbmclassi...           0.755036   \n",
       "2   {'lgbmclassifier__num_leaves': 30, 'lgbmclassi...           0.755880   \n",
       "3   {'lgbmclassifier__num_leaves': 40, 'lgbmclassi...           0.755804   \n",
       "4   {'lgbmclassifier__num_leaves': 50, 'lgbmclassi...           0.757185   \n",
       "5   {'lgbmclassifier__num_leaves': 60, 'lgbmclassi...           0.758068   \n",
       "6   {'lgbmclassifier__num_leaves': 70, 'lgbmclassi...           0.757492   \n",
       "7   {'lgbmclassifier__num_leaves': 80, 'lgbmclassi...           0.757914   \n",
       "8   {'lgbmclassifier__num_leaves': 90, 'lgbmclassi...           0.757799   \n",
       "9   {'lgbmclassifier__num_leaves': 100, 'lgbmclass...           0.757530   \n",
       "10  {'lgbmclassifier__num_leaves': 110, 'lgbmclass...           0.757492   \n",
       "11  {'lgbmclassifier__num_leaves': 120, 'lgbmclass...           0.757761   \n",
       "12  {'lgbmclassifier__num_leaves': 130, 'lgbmclass...           0.758643   \n",
       "13  {'lgbmclassifier__num_leaves': 140, 'lgbmclass...           0.759104   \n",
       "14  {'lgbmclassifier__num_leaves': 150, 'lgbmclass...           0.758490   \n",
       "15  {'lgbmclassifier__num_leaves': 160, 'lgbmclass...           0.757991   \n",
       "16  {'lgbmclassifier__num_leaves': 170, 'lgbmclass...           0.757377   \n",
       "17  {'lgbmclassifier__num_leaves': 180, 'lgbmclass...           0.757914   \n",
       "18  {'lgbmclassifier__num_leaves': 190, 'lgbmclass...           0.757032   \n",
       "19  {'lgbmclassifier__num_leaves': 200, 'lgbmclass...           0.759641   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.755334           0.752571           0.749962   \n",
       "1            0.756754           0.754029           0.752379   \n",
       "2            0.758404           0.753607           0.753185   \n",
       "3            0.758173           0.754029           0.753377   \n",
       "4            0.758058           0.755449           0.754183   \n",
       "5            0.758250           0.754873           0.754106   \n",
       "6            0.758596           0.756485           0.753684   \n",
       "7            0.758557           0.756408           0.754183   \n",
       "8            0.758787           0.755909           0.754682   \n",
       "9            0.759171           0.755756           0.754528   \n",
       "10           0.759977           0.756523           0.754490   \n",
       "11           0.760476           0.757176           0.754797   \n",
       "12           0.759632           0.755487           0.754682   \n",
       "13           0.759018           0.756025           0.755449   \n",
       "14           0.759478           0.756600           0.754528   \n",
       "15           0.758327           0.756101           0.755602   \n",
       "16           0.759785           0.757790           0.754873   \n",
       "17           0.758596           0.757022           0.755104   \n",
       "18           0.759286           0.757137           0.755295   \n",
       "19           0.758519           0.755948           0.755449   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.759133           0.752187           0.755986   \n",
       "1            0.760860           0.753569           0.756907   \n",
       "2            0.762087           0.754068           0.756984   \n",
       "3            0.761896           0.754566           0.758135   \n",
       "4            0.762970           0.755257           0.758979   \n",
       "5            0.763661           0.755257           0.759018   \n",
       "6            0.763124           0.754375           0.758557   \n",
       "7            0.764006           0.755142           0.760015   \n",
       "8            0.763968           0.755833           0.760169   \n",
       "9            0.764121           0.755679           0.759286   \n",
       "10           0.763776           0.755641           0.760092   \n",
       "11           0.763431           0.757022           0.760783   \n",
       "12           0.763008           0.758135           0.759363   \n",
       "13           0.763200           0.757828           0.760322   \n",
       "14           0.763622           0.756754           0.760706   \n",
       "15           0.763546           0.756523           0.759632   \n",
       "16           0.762740           0.756178           0.760860   \n",
       "17           0.763392           0.756408           0.761090   \n",
       "18           0.763699           0.757061           0.760054   \n",
       "19           0.763162           0.757176           0.760399   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.757099           0.757406           0.754144         0.754564   \n",
       "1            0.759478           0.758941           0.755180         0.756313   \n",
       "2            0.758787           0.759517           0.755065         0.756758   \n",
       "3            0.760092           0.759363           0.756216         0.757165   \n",
       "4            0.760898           0.760975           0.756792         0.758075   \n",
       "5            0.760936           0.759977           0.756332         0.758048   \n",
       "6            0.762471           0.760169           0.757214         0.758217   \n",
       "7            0.761857           0.761781           0.756677         0.758654   \n",
       "8            0.761550           0.760744           0.757291         0.758673   \n",
       "9            0.763699           0.761167           0.757176         0.758811   \n",
       "10           0.761896           0.760169           0.758365         0.758842   \n",
       "11           0.762932           0.760629           0.757598         0.759260   \n",
       "12           0.762778           0.760130           0.757406         0.758926   \n",
       "13           0.763162           0.761665           0.756639         0.759241   \n",
       "14           0.763431           0.761857           0.757099         0.759256   \n",
       "15           0.762510           0.761051           0.758135         0.758942   \n",
       "16           0.761512           0.761435           0.757099         0.758965   \n",
       "17           0.763354           0.761627           0.757291         0.759180   \n",
       "18           0.763584           0.761282           0.757943         0.759237   \n",
       "19           0.763507           0.759440           0.756332         0.758957   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.002767               20  \n",
       "1         0.002632               19  \n",
       "2         0.002765               18  \n",
       "3         0.002673               17  \n",
       "4         0.002713               15  \n",
       "5         0.002844               16  \n",
       "6         0.002934               14  \n",
       "7         0.003039               13  \n",
       "8         0.002778               12  \n",
       "9         0.003159               11  \n",
       "10        0.002737               10  \n",
       "11        0.002661                1  \n",
       "12        0.002579                9  \n",
       "13        0.002677                3  \n",
       "14        0.002938                2  \n",
       "15        0.002566                8  \n",
       "16        0.002510                6  \n",
       "17        0.002815                5  \n",
       "18        0.002736                4  \n",
       "19        0.002698                7  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 530.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.relplot(data=result_df,\n",
    "\tkind='line',\n",
    "\tx='param_lgbmclassifier__num_leaves',\n",
    "\ty='mean_test_score',\n",
    "\thue='param_lgbmclassifier__objective',\n",
    "\t#col='param_classifier__p'\n",
    "           )\n",
    "\n",
    "g.set_titles('evolucion de scores por cantidad de hojas usadas - LightGBM')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'scaler':[StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
    "    'lgbmclassifier__learning_rate': [0.01, 0.05, 0.1], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    #'lgbmclassifier__num_leaves': [10, 50, 100, 150, 175 200, 225, 250, 275, 300], \n",
    "    #'lgbmclassifier__num_iterations': [10, 15, 20], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    'lgbmclassifier__max_depth': [10, 50, 100, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lgbmclassifier',\n",
       "                                        LGBMClassifier(random_state=2021))]),\n",
       "             param_grid={'lgbmclassifier__learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'lgbmclassifier__max_depth': [10, 50, 100, 150, 175,\n",
       "                                                       200, 225, 250, 275,\n",
       "                                                       300],\n",
       "                         'lgbmclassifier__objective': ['regression']})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617890952068488"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgbmclassifier__learning_rate': 0.1, 'lgbmclassifier__max_depth': 50, 'lgbmclassifier__objective': 'regression'}\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lgbmclassifier',\n",
      "                 LGBMClassifier(max_depth=50, objective='regression',\n",
      "                                random_state=2021))])\n"
     ]
    }
   ],
   "source": [
    "# Access the best set of parameters\n",
    "best_params = gs.best_params_\n",
    "print(best_params)\n",
    "# Stores the optimum model in best_pipe\n",
    "best_pipe = gs.best_estimator_\n",
    "print(best_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_lgbmclassifier__learning_rate',\n",
      "       'param_lgbmclassifier__max_depth', 'param_lgbmclassifier__objective',\n",
      "       'params', 'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
      "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
      "       'std_test_score', 'rank_test_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(gs.cv_results_, orient='columns')\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lgbmclassifier__learning_rate</th>\n",
       "      <th>param_lgbmclassifier__max_depth</th>\n",
       "      <th>param_lgbmclassifier__objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.393009</td>\n",
       "      <td>0.576685</td>\n",
       "      <td>0.370357</td>\n",
       "      <td>0.040636</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.882898</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>0.352737</td>\n",
       "      <td>0.037549</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.659380</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.336542</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.708688</td>\n",
       "      <td>0.174315</td>\n",
       "      <td>0.357509</td>\n",
       "      <td>0.033317</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.612076</td>\n",
       "      <td>0.105466</td>\n",
       "      <td>0.339967</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.01</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.534542</td>\n",
       "      <td>0.161139</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.026136</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.844571</td>\n",
       "      <td>0.235400</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.01</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.685402</td>\n",
       "      <td>0.161266</td>\n",
       "      <td>0.337116</td>\n",
       "      <td>0.025812</td>\n",
       "      <td>0.01</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.897485</td>\n",
       "      <td>0.157077</td>\n",
       "      <td>0.338547</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>0.01</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.913765</td>\n",
       "      <td>0.279080</td>\n",
       "      <td>0.323447</td>\n",
       "      <td>0.029426</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.645632</td>\n",
       "      <td>0.046469</td>\n",
       "      <td>0.464581</td>\n",
       "      <td>0.044891</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755991</td>\n",
       "      <td>0.752034</td>\n",
       "      <td>0.756236</td>\n",
       "      <td>0.757483</td>\n",
       "      <td>0.755948</td>\n",
       "      <td>0.755538</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.854978</td>\n",
       "      <td>0.273230</td>\n",
       "      <td>0.489626</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.774570</td>\n",
       "      <td>0.134759</td>\n",
       "      <td>0.489724</td>\n",
       "      <td>0.040040</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.801131</td>\n",
       "      <td>0.167093</td>\n",
       "      <td>0.562892</td>\n",
       "      <td>0.099310</td>\n",
       "      <td>0.05</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.951797</td>\n",
       "      <td>0.263496</td>\n",
       "      <td>0.492938</td>\n",
       "      <td>0.036891</td>\n",
       "      <td>0.05</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.625626</td>\n",
       "      <td>0.147011</td>\n",
       "      <td>0.463454</td>\n",
       "      <td>0.044923</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.710643</td>\n",
       "      <td>0.108743</td>\n",
       "      <td>0.459066</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.05</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.889226</td>\n",
       "      <td>0.303339</td>\n",
       "      <td>0.479145</td>\n",
       "      <td>0.047034</td>\n",
       "      <td>0.05</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.813100</td>\n",
       "      <td>0.178809</td>\n",
       "      <td>0.481052</td>\n",
       "      <td>0.055865</td>\n",
       "      <td>0.05</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.932214</td>\n",
       "      <td>0.246114</td>\n",
       "      <td>0.501327</td>\n",
       "      <td>0.068610</td>\n",
       "      <td>0.05</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.476625</td>\n",
       "      <td>0.191447</td>\n",
       "      <td>0.452485</td>\n",
       "      <td>0.034667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.756624</td>\n",
       "      <td>0.753281</td>\n",
       "      <td>0.757080</td>\n",
       "      <td>0.759210</td>\n",
       "      <td>0.756811</td>\n",
       "      <td>0.756601</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.406136</td>\n",
       "      <td>0.137646</td>\n",
       "      <td>0.498342</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.428647</td>\n",
       "      <td>0.277231</td>\n",
       "      <td>0.462923</td>\n",
       "      <td>0.056136</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.487062</td>\n",
       "      <td>0.139051</td>\n",
       "      <td>0.435471</td>\n",
       "      <td>0.040988</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.356127</td>\n",
       "      <td>0.215958</td>\n",
       "      <td>0.475671</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.189736</td>\n",
       "      <td>0.103694</td>\n",
       "      <td>0.486532</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.327119</td>\n",
       "      <td>0.214745</td>\n",
       "      <td>0.461178</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.1</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.476178</td>\n",
       "      <td>0.173307</td>\n",
       "      <td>0.438535</td>\n",
       "      <td>0.050507</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.381680</td>\n",
       "      <td>0.146802</td>\n",
       "      <td>0.463335</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.1</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.559032</td>\n",
       "      <td>0.264998</td>\n",
       "      <td>0.473744</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        5.393009      0.576685         0.370357        0.040636   \n",
       "1        4.882898      0.401493         0.352737        0.037549   \n",
       "2        4.659380      0.112408         0.336542        0.034890   \n",
       "3        4.708688      0.174315         0.357509        0.033317   \n",
       "4        4.612076      0.105466         0.339967        0.033908   \n",
       "5        4.534542      0.161139         0.339244        0.026136   \n",
       "6        4.844571      0.235400         0.353835        0.027192   \n",
       "7        4.685402      0.161266         0.337116        0.025812   \n",
       "8        4.897485      0.157077         0.338547        0.036404   \n",
       "9        4.913765      0.279080         0.323447        0.029426   \n",
       "10       4.645632      0.046469         0.464581        0.044891   \n",
       "11       4.854978      0.273230         0.489626        0.035991   \n",
       "12       4.774570      0.134759         0.489724        0.040040   \n",
       "13       4.801131      0.167093         0.562892        0.099310   \n",
       "14       4.951797      0.263496         0.492938        0.036891   \n",
       "15       4.625626      0.147011         0.463454        0.044923   \n",
       "16       4.710643      0.108743         0.459066        0.029431   \n",
       "17       4.889226      0.303339         0.479145        0.047034   \n",
       "18       4.813100      0.178809         0.481052        0.055865   \n",
       "19       4.932214      0.246114         0.501327        0.068610   \n",
       "20       4.476625      0.191447         0.452485        0.034667   \n",
       "21       4.406136      0.137646         0.498342        0.005022   \n",
       "22       4.428647      0.277231         0.462923        0.056136   \n",
       "23       4.487062      0.139051         0.435471        0.040988   \n",
       "24       4.356127      0.215958         0.475671        0.040076   \n",
       "25       4.189736      0.103694         0.486532        0.012581   \n",
       "26       4.327119      0.214745         0.461178        0.029130   \n",
       "27       4.476178      0.173307         0.438535        0.050507   \n",
       "28       4.381680      0.146802         0.463335        0.034573   \n",
       "29       4.559032      0.264998         0.473744        0.019738   \n",
       "\n",
       "   param_lgbmclassifier__learning_rate param_lgbmclassifier__max_depth  \\\n",
       "0                                 0.01                              10   \n",
       "1                                 0.01                              50   \n",
       "2                                 0.01                             100   \n",
       "3                                 0.01                             150   \n",
       "4                                 0.01                             175   \n",
       "5                                 0.01                             200   \n",
       "6                                 0.01                             225   \n",
       "7                                 0.01                             250   \n",
       "8                                 0.01                             275   \n",
       "9                                 0.01                             300   \n",
       "10                                0.05                              10   \n",
       "11                                0.05                              50   \n",
       "12                                0.05                             100   \n",
       "13                                0.05                             150   \n",
       "14                                0.05                             175   \n",
       "15                                0.05                             200   \n",
       "16                                0.05                             225   \n",
       "17                                0.05                             250   \n",
       "18                                0.05                             275   \n",
       "19                                0.05                             300   \n",
       "20                                 0.1                              10   \n",
       "21                                 0.1                              50   \n",
       "22                                 0.1                             100   \n",
       "23                                 0.1                             150   \n",
       "24                                 0.1                             175   \n",
       "25                                 0.1                             200   \n",
       "26                                 0.1                             225   \n",
       "27                                 0.1                             250   \n",
       "28                                 0.1                             275   \n",
       "29                                 0.1                             300   \n",
       "\n",
       "   param_lgbmclassifier__objective  \\\n",
       "0                       regression   \n",
       "1                       regression   \n",
       "2                       regression   \n",
       "3                       regression   \n",
       "4                       regression   \n",
       "5                       regression   \n",
       "6                       regression   \n",
       "7                       regression   \n",
       "8                       regression   \n",
       "9                       regression   \n",
       "10                      regression   \n",
       "11                      regression   \n",
       "12                      regression   \n",
       "13                      regression   \n",
       "14                      regression   \n",
       "15                      regression   \n",
       "16                      regression   \n",
       "17                      regression   \n",
       "18                      regression   \n",
       "19                      regression   \n",
       "20                      regression   \n",
       "21                      regression   \n",
       "22                      regression   \n",
       "23                      regression   \n",
       "24                      regression   \n",
       "25                      regression   \n",
       "26                      regression   \n",
       "27                      regression   \n",
       "28                      regression   \n",
       "29                      regression   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "1   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "2   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "3   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "4   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "5   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "6   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "7   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "8   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "9   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "10  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755991   \n",
       "11  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "12  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "13  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "14  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "15  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "16  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "17  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "18  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "19  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "20  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.756624   \n",
       "21  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "22  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "23  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "24  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "25  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "26  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "27  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "28  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "29  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.738277           0.743573           0.744302   \n",
       "1            0.738277           0.743573           0.744302   \n",
       "2            0.738277           0.743573           0.744302   \n",
       "3            0.738277           0.743573           0.744302   \n",
       "4            0.738277           0.743573           0.744302   \n",
       "5            0.738277           0.743573           0.744302   \n",
       "6            0.738277           0.743573           0.744302   \n",
       "7            0.738277           0.743573           0.744302   \n",
       "8            0.738277           0.743573           0.744302   \n",
       "9            0.738277           0.743573           0.744302   \n",
       "10           0.752034           0.756236           0.757483   \n",
       "11           0.752245           0.756581           0.757521   \n",
       "12           0.752245           0.756581           0.757521   \n",
       "13           0.752245           0.756581           0.757521   \n",
       "14           0.752245           0.756581           0.757521   \n",
       "15           0.752245           0.756581           0.757521   \n",
       "16           0.752245           0.756581           0.757521   \n",
       "17           0.752245           0.756581           0.757521   \n",
       "18           0.752245           0.756581           0.757521   \n",
       "19           0.752245           0.756581           0.757521   \n",
       "20           0.753281           0.757080           0.759210   \n",
       "21           0.753837           0.757809           0.758787   \n",
       "22           0.753837           0.757809           0.758787   \n",
       "23           0.753837           0.757809           0.758787   \n",
       "24           0.753837           0.757809           0.758787   \n",
       "25           0.753837           0.757809           0.758787   \n",
       "26           0.753837           0.757809           0.758787   \n",
       "27           0.753837           0.757809           0.758787   \n",
       "28           0.753837           0.757809           0.758787   \n",
       "29           0.753837           0.757809           0.758787   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.741117         0.741927        0.002122               21  \n",
       "1            0.741117         0.741927        0.002122               21  \n",
       "2            0.741117         0.741927        0.002122               21  \n",
       "3            0.741117         0.741927        0.002122               21  \n",
       "4            0.741117         0.741927        0.002122               21  \n",
       "5            0.741117         0.741927        0.002122               21  \n",
       "6            0.741117         0.741927        0.002122               21  \n",
       "7            0.741117         0.741927        0.002122               21  \n",
       "8            0.741117         0.741927        0.002122               21  \n",
       "9            0.741117         0.741927        0.002122               21  \n",
       "10           0.755948         0.755538        0.001840               20  \n",
       "11           0.755602         0.755554        0.001786               11  \n",
       "12           0.755602         0.755554        0.001786               11  \n",
       "13           0.755602         0.755554        0.001786               11  \n",
       "14           0.755602         0.755554        0.001786               11  \n",
       "15           0.755602         0.755554        0.001786               11  \n",
       "16           0.755602         0.755554        0.001786               11  \n",
       "17           0.755602         0.755554        0.001786               11  \n",
       "18           0.755602         0.755554        0.001786               11  \n",
       "19           0.755602         0.755554        0.001786               11  \n",
       "20           0.756811         0.756601        0.001903               10  \n",
       "21           0.757195         0.756954        0.001667                1  \n",
       "22           0.757195         0.756954        0.001667                1  \n",
       "23           0.757195         0.756954        0.001667                1  \n",
       "24           0.757195         0.756954        0.001667                1  \n",
       "25           0.757195         0.756954        0.001667                1  \n",
       "26           0.757195         0.756954        0.001667                1  \n",
       "27           0.757195         0.756954        0.001667                1  \n",
       "28           0.757195         0.756954        0.001667                1  \n",
       "29           0.757195         0.756954        0.001667                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.relplot(data=result_df,\n",
    "\tkind='line',\n",
    "\tx='param_lgbmclassifier__max_depth',\n",
    "\ty='mean_test_score',\n",
    "\tcol='param_lgbmclassifier__learning_rate'\n",
    "           )\n",
    "\n",
    "#g.set_titles('evolucion de scores por cantidad de hojas usadas {param_lgbmclassifier__objective}')\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'scaler':[StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
    "    'lgbmclassifier__learning_rate': [0.01, 0.05, 0.1], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    'lgbmclassifier__num_leaves': [10, 50, 100, 150, 175, 200, 225, 250, 275, 300], \n",
    "    #'lgbmclassifier__num_iterations': [10, 15, 20], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    #'lgbmclassifier__max_depth': [10, 50, 100, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lgbmclassifier',\n",
       "                                        LGBMClassifier(random_state=2021))]),\n",
       "             param_grid={'lgbmclassifier__learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'lgbmclassifier__num_leaves': [10, 50, 100, 150, 175,\n",
       "                                                        200, 225, 250, 275,\n",
       "                                                        300],\n",
       "                         'lgbmclassifier__objective': ['regression']})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7850161741512887"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgbmclassifier__learning_rate': 0.05, 'lgbmclassifier__num_leaves': 300, 'lgbmclassifier__objective': 'regression'}\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lgbmclassifier',\n",
      "                 LGBMClassifier(learning_rate=0.05, num_leaves=300,\n",
      "                                objective='regression', random_state=2021))])\n"
     ]
    }
   ],
   "source": [
    "# Access the best set of parameters\n",
    "best_params = gs.best_params_\n",
    "print(best_params)\n",
    "# Stores the optimum model in best_pipe\n",
    "best_pipe = gs.best_estimator_\n",
    "print(best_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_lgbmclassifier__learning_rate',\n",
      "       'param_lgbmclassifier__num_leaves', 'param_lgbmclassifier__objective',\n",
      "       'params', 'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
      "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
      "       'std_test_score', 'rank_test_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(gs.cv_results_, orient='columns')\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lgbmclassifier__learning_rate</th>\n",
       "      <th>param_lgbmclassifier__num_leaves</th>\n",
       "      <th>param_lgbmclassifier__objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.416429</td>\n",
       "      <td>0.699582</td>\n",
       "      <td>0.333020</td>\n",
       "      <td>0.109526</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.736287</td>\n",
       "      <td>0.732982</td>\n",
       "      <td>0.737318</td>\n",
       "      <td>0.737529</td>\n",
       "      <td>0.733269</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.785387</td>\n",
       "      <td>0.136541</td>\n",
       "      <td>0.470083</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.744038</td>\n",
       "      <td>0.741884</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>0.747583</td>\n",
       "      <td>0.744340</td>\n",
       "      <td>0.744963</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.126427</td>\n",
       "      <td>0.165306</td>\n",
       "      <td>0.570049</td>\n",
       "      <td>0.050663</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.746935</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.750844</td>\n",
       "      <td>0.750518</td>\n",
       "      <td>0.747352</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.509085</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.745318</td>\n",
       "      <td>0.751228</td>\n",
       "      <td>0.751228</td>\n",
       "      <td>0.748312</td>\n",
       "      <td>0.748957</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.101719</td>\n",
       "      <td>0.448956</td>\n",
       "      <td>0.675886</td>\n",
       "      <td>0.074435</td>\n",
       "      <td>0.01</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.748988</td>\n",
       "      <td>0.746431</td>\n",
       "      <td>0.751669</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.749252</td>\n",
       "      <td>0.749717</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.409874</td>\n",
       "      <td>0.217027</td>\n",
       "      <td>0.730046</td>\n",
       "      <td>0.063101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.749218</td>\n",
       "      <td>0.746853</td>\n",
       "      <td>0.751765</td>\n",
       "      <td>0.752571</td>\n",
       "      <td>0.749482</td>\n",
       "      <td>0.749978</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.712694</td>\n",
       "      <td>0.076609</td>\n",
       "      <td>0.764548</td>\n",
       "      <td>0.071673</td>\n",
       "      <td>0.01</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.750484</td>\n",
       "      <td>0.747026</td>\n",
       "      <td>0.752590</td>\n",
       "      <td>0.752724</td>\n",
       "      <td>0.749674</td>\n",
       "      <td>0.750500</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.229115</td>\n",
       "      <td>0.137577</td>\n",
       "      <td>0.792487</td>\n",
       "      <td>0.043060</td>\n",
       "      <td>0.01</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.750350</td>\n",
       "      <td>0.747429</td>\n",
       "      <td>0.752456</td>\n",
       "      <td>0.752398</td>\n",
       "      <td>0.749827</td>\n",
       "      <td>0.750492</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.789955</td>\n",
       "      <td>0.148621</td>\n",
       "      <td>0.883318</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.01</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.750772</td>\n",
       "      <td>0.747429</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.750230</td>\n",
       "      <td>0.750707</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.104770</td>\n",
       "      <td>0.100973</td>\n",
       "      <td>0.823469</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.750983</td>\n",
       "      <td>0.747583</td>\n",
       "      <td>0.752667</td>\n",
       "      <td>0.752801</td>\n",
       "      <td>0.750691</td>\n",
       "      <td>0.750945</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.896147</td>\n",
       "      <td>0.121867</td>\n",
       "      <td>0.358992</td>\n",
       "      <td>0.040520</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.751943</td>\n",
       "      <td>0.750480</td>\n",
       "      <td>0.754068</td>\n",
       "      <td>0.754010</td>\n",
       "      <td>0.753300</td>\n",
       "      <td>0.752760</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.737431</td>\n",
       "      <td>0.103710</td>\n",
       "      <td>0.656547</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757065</td>\n",
       "      <td>0.753569</td>\n",
       "      <td>0.758001</td>\n",
       "      <td>0.758979</td>\n",
       "      <td>0.756984</td>\n",
       "      <td>0.756920</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.911211</td>\n",
       "      <td>0.137212</td>\n",
       "      <td>0.772206</td>\n",
       "      <td>0.070277</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.758236</td>\n",
       "      <td>0.755046</td>\n",
       "      <td>0.759440</td>\n",
       "      <td>0.760668</td>\n",
       "      <td>0.758576</td>\n",
       "      <td>0.758393</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.748182</td>\n",
       "      <td>0.064536</td>\n",
       "      <td>0.815682</td>\n",
       "      <td>0.079694</td>\n",
       "      <td>0.05</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.759291</td>\n",
       "      <td>0.755487</td>\n",
       "      <td>0.759651</td>\n",
       "      <td>0.760994</td>\n",
       "      <td>0.758903</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.938579</td>\n",
       "      <td>1.319458</td>\n",
       "      <td>0.853285</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>0.05</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.759003</td>\n",
       "      <td>0.756101</td>\n",
       "      <td>0.760035</td>\n",
       "      <td>0.760879</td>\n",
       "      <td>0.759344</td>\n",
       "      <td>0.759072</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.699681</td>\n",
       "      <td>0.136090</td>\n",
       "      <td>0.883560</td>\n",
       "      <td>0.049675</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.759118</td>\n",
       "      <td>0.755718</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>0.760572</td>\n",
       "      <td>0.759210</td>\n",
       "      <td>0.758850</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.481194</td>\n",
       "      <td>0.543445</td>\n",
       "      <td>0.912733</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.05</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.759425</td>\n",
       "      <td>0.755622</td>\n",
       "      <td>0.760015</td>\n",
       "      <td>0.760553</td>\n",
       "      <td>0.759286</td>\n",
       "      <td>0.758980</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.904958</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>0.916467</td>\n",
       "      <td>0.073627</td>\n",
       "      <td>0.05</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.758926</td>\n",
       "      <td>0.755737</td>\n",
       "      <td>0.760303</td>\n",
       "      <td>0.760860</td>\n",
       "      <td>0.760035</td>\n",
       "      <td>0.759172</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.858318</td>\n",
       "      <td>0.207822</td>\n",
       "      <td>1.012098</td>\n",
       "      <td>0.060929</td>\n",
       "      <td>0.05</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.758830</td>\n",
       "      <td>0.756274</td>\n",
       "      <td>0.760744</td>\n",
       "      <td>0.760226</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.759130</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.209336</td>\n",
       "      <td>0.088793</td>\n",
       "      <td>1.113877</td>\n",
       "      <td>0.089813</td>\n",
       "      <td>0.05</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.758466</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.760514</td>\n",
       "      <td>0.761224</td>\n",
       "      <td>0.759823</td>\n",
       "      <td>0.759191</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.725162</td>\n",
       "      <td>0.157439</td>\n",
       "      <td>0.425126</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.754360</td>\n",
       "      <td>0.751074</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.754847</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.016343</td>\n",
       "      <td>0.163964</td>\n",
       "      <td>0.609975</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758140</td>\n",
       "      <td>0.754931</td>\n",
       "      <td>0.758883</td>\n",
       "      <td>0.759555</td>\n",
       "      <td>0.758001</td>\n",
       "      <td>0.757902</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.019267</td>\n",
       "      <td>0.244111</td>\n",
       "      <td>0.653956</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757698</td>\n",
       "      <td>0.755890</td>\n",
       "      <td>0.759536</td>\n",
       "      <td>0.760994</td>\n",
       "      <td>0.759267</td>\n",
       "      <td>0.758677</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.875219</td>\n",
       "      <td>0.170602</td>\n",
       "      <td>0.742345</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758485</td>\n",
       "      <td>0.755449</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.760668</td>\n",
       "      <td>0.759190</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.609813</td>\n",
       "      <td>0.702174</td>\n",
       "      <td>0.736427</td>\n",
       "      <td>0.059165</td>\n",
       "      <td>0.1</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757372</td>\n",
       "      <td>0.755679</td>\n",
       "      <td>0.758691</td>\n",
       "      <td>0.760092</td>\n",
       "      <td>0.759804</td>\n",
       "      <td>0.758328</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.578558</td>\n",
       "      <td>0.085899</td>\n",
       "      <td>0.848109</td>\n",
       "      <td>0.102289</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758696</td>\n",
       "      <td>0.755219</td>\n",
       "      <td>0.759133</td>\n",
       "      <td>0.759785</td>\n",
       "      <td>0.759421</td>\n",
       "      <td>0.758451</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.998035</td>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.806763</td>\n",
       "      <td>0.079395</td>\n",
       "      <td>0.1</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758466</td>\n",
       "      <td>0.755008</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.760668</td>\n",
       "      <td>0.758998</td>\n",
       "      <td>0.758581</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.585935</td>\n",
       "      <td>0.270469</td>\n",
       "      <td>0.867031</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757219</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.760092</td>\n",
       "      <td>0.759075</td>\n",
       "      <td>0.758672</td>\n",
       "      <td>0.758174</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.658784</td>\n",
       "      <td>0.070904</td>\n",
       "      <td>0.917438</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>0.1</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758696</td>\n",
       "      <td>0.755622</td>\n",
       "      <td>0.759708</td>\n",
       "      <td>0.760303</td>\n",
       "      <td>0.759708</td>\n",
       "      <td>0.758808</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.922867</td>\n",
       "      <td>0.098273</td>\n",
       "      <td>0.971115</td>\n",
       "      <td>0.037043</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757890</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.759958</td>\n",
       "      <td>0.759325</td>\n",
       "      <td>0.758864</td>\n",
       "      <td>0.758121</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        4.416429      0.699582         0.333020        0.109526   \n",
       "1        5.785387      0.136541         0.470083        0.057279   \n",
       "2        7.126427      0.165306         0.570049        0.050663   \n",
       "3        8.509085      0.185861         0.618544        0.062128   \n",
       "4        9.101719      0.448956         0.675886        0.074435   \n",
       "5        9.409874      0.217027         0.730046        0.063101   \n",
       "6        9.712694      0.076609         0.764548        0.071673   \n",
       "7       10.229115      0.137577         0.792487        0.043060   \n",
       "8       10.789955      0.148621         0.883318        0.035110   \n",
       "9       11.104770      0.100973         0.823469        0.064815   \n",
       "10       3.896147      0.121867         0.358992        0.040520   \n",
       "11       5.737431      0.103710         0.656547        0.056700   \n",
       "12       6.911211      0.137212         0.772206        0.070277   \n",
       "13       7.748182      0.064536         0.815682        0.079694   \n",
       "14       8.938579      1.319458         0.853285        0.032103   \n",
       "15       8.699681      0.136090         0.883560        0.049675   \n",
       "16       9.481194      0.543445         0.912733        0.034531   \n",
       "17       9.904958      0.284162         0.916467        0.073627   \n",
       "18       9.858318      0.207822         1.012098        0.060929   \n",
       "19      10.209336      0.088793         1.113877        0.089813   \n",
       "20       3.725162      0.157439         0.425126        0.057993   \n",
       "21       5.016343      0.163964         0.609975        0.042335   \n",
       "22       6.019267      0.244111         0.653956        0.052700   \n",
       "23       6.875219      0.170602         0.742345        0.027816   \n",
       "24       7.609813      0.702174         0.736427        0.059165   \n",
       "25       7.578558      0.085899         0.848109        0.102289   \n",
       "26       7.998035      0.404129         0.806763        0.079395   \n",
       "27       8.585935      0.270469         0.867031        0.028599   \n",
       "28       8.658784      0.070904         0.917438        0.037621   \n",
       "29       8.922867      0.098273         0.971115        0.037043   \n",
       "\n",
       "   param_lgbmclassifier__learning_rate param_lgbmclassifier__num_leaves  \\\n",
       "0                                 0.01                               10   \n",
       "1                                 0.01                               50   \n",
       "2                                 0.01                              100   \n",
       "3                                 0.01                              150   \n",
       "4                                 0.01                              175   \n",
       "5                                 0.01                              200   \n",
       "6                                 0.01                              225   \n",
       "7                                 0.01                              250   \n",
       "8                                 0.01                              275   \n",
       "9                                 0.01                              300   \n",
       "10                                0.05                               10   \n",
       "11                                0.05                               50   \n",
       "12                                0.05                              100   \n",
       "13                                0.05                              150   \n",
       "14                                0.05                              175   \n",
       "15                                0.05                              200   \n",
       "16                                0.05                              225   \n",
       "17                                0.05                              250   \n",
       "18                                0.05                              275   \n",
       "19                                0.05                              300   \n",
       "20                                 0.1                               10   \n",
       "21                                 0.1                               50   \n",
       "22                                 0.1                              100   \n",
       "23                                 0.1                              150   \n",
       "24                                 0.1                              175   \n",
       "25                                 0.1                              200   \n",
       "26                                 0.1                              225   \n",
       "27                                 0.1                              250   \n",
       "28                                 0.1                              275   \n",
       "29                                 0.1                              300   \n",
       "\n",
       "   param_lgbmclassifier__objective  \\\n",
       "0                       regression   \n",
       "1                       regression   \n",
       "2                       regression   \n",
       "3                       regression   \n",
       "4                       regression   \n",
       "5                       regression   \n",
       "6                       regression   \n",
       "7                       regression   \n",
       "8                       regression   \n",
       "9                       regression   \n",
       "10                      regression   \n",
       "11                      regression   \n",
       "12                      regression   \n",
       "13                      regression   \n",
       "14                      regression   \n",
       "15                      regression   \n",
       "16                      regression   \n",
       "17                      regression   \n",
       "18                      regression   \n",
       "19                      regression   \n",
       "20                      regression   \n",
       "21                      regression   \n",
       "22                      regression   \n",
       "23                      regression   \n",
       "24                      regression   \n",
       "25                      regression   \n",
       "26                      regression   \n",
       "27                      regression   \n",
       "28                      regression   \n",
       "29                      regression   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.736287   \n",
       "1   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.744038   \n",
       "2   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.746935   \n",
       "3   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.748700   \n",
       "4   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.748988   \n",
       "5   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.749218   \n",
       "6   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.750484   \n",
       "7   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.750350   \n",
       "8   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.750772   \n",
       "9   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.750983   \n",
       "10  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.751943   \n",
       "11  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757065   \n",
       "12  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.758236   \n",
       "13  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.759291   \n",
       "14  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.759003   \n",
       "15  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.759118   \n",
       "16  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.759425   \n",
       "17  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.758926   \n",
       "18  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.758830   \n",
       "19  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.758466   \n",
       "20  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.754360   \n",
       "21  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758140   \n",
       "22  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757698   \n",
       "23  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758485   \n",
       "24  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757372   \n",
       "25  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758696   \n",
       "26  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758466   \n",
       "27  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757219   \n",
       "28  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758696   \n",
       "29  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757890   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.732982           0.737318           0.737529   \n",
       "1            0.741884           0.746969           0.747583   \n",
       "2            0.744186           0.750844           0.750518   \n",
       "3            0.745318           0.751228           0.751228   \n",
       "4            0.746431           0.751669           0.752245   \n",
       "5            0.746853           0.751765           0.752571   \n",
       "6            0.747026           0.752590           0.752724   \n",
       "7            0.747429           0.752456           0.752398   \n",
       "8            0.747429           0.752552           0.752552   \n",
       "9            0.747583           0.752667           0.752801   \n",
       "10           0.750480           0.754068           0.754010   \n",
       "11           0.753569           0.758001           0.758979   \n",
       "12           0.755046           0.759440           0.760668   \n",
       "13           0.755487           0.759651           0.760994   \n",
       "14           0.756101           0.760035           0.760879   \n",
       "15           0.755718           0.759632           0.760572   \n",
       "16           0.755622           0.760015           0.760553   \n",
       "17           0.755737           0.760303           0.760860   \n",
       "18           0.756274           0.760744           0.760226   \n",
       "19           0.755929           0.760514           0.761224   \n",
       "20           0.751074           0.756216           0.756370   \n",
       "21           0.754931           0.758883           0.759555   \n",
       "22           0.755890           0.759536           0.760994   \n",
       "23           0.755449           0.759574           0.760668   \n",
       "24           0.755679           0.758691           0.760092   \n",
       "25           0.755219           0.759133           0.759785   \n",
       "26           0.755008           0.759766           0.760668   \n",
       "27           0.755814           0.760092           0.759075   \n",
       "28           0.755622           0.759708           0.760303   \n",
       "29           0.754566           0.759958           0.759325   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.733269         0.735477        0.001967               30  \n",
       "1            0.744340         0.744963        0.002079               29  \n",
       "2            0.747352         0.747967        0.002471               28  \n",
       "3            0.748312         0.748957        0.002193               27  \n",
       "4            0.749252         0.749717        0.002085               26  \n",
       "5            0.749482         0.749978        0.002025               25  \n",
       "6            0.749674         0.750500        0.002101               23  \n",
       "7            0.749827         0.750492        0.001862               24  \n",
       "8            0.750230         0.750707        0.001886               22  \n",
       "9            0.750691         0.750945        0.001886               21  \n",
       "10           0.753300         0.752760        0.001373               20  \n",
       "11           0.756984         0.756920        0.001826               18  \n",
       "12           0.758576         0.758393        0.001872               13  \n",
       "13           0.758903         0.758865        0.001830                6  \n",
       "14           0.759344         0.759072        0.001618                4  \n",
       "15           0.759210         0.758850        0.001649                7  \n",
       "16           0.759286         0.758980        0.001739                5  \n",
       "17           0.760035         0.759172        0.001829                2  \n",
       "18           0.759574         0.759130        0.001565                3  \n",
       "19           0.759823         0.759191        0.001868                1  \n",
       "20           0.756216         0.754847        0.002027               19  \n",
       "21           0.758001         0.757902        0.001587               17  \n",
       "22           0.759267         0.758677        0.001742                9  \n",
       "23           0.759190         0.758673        0.001760               10  \n",
       "24           0.759804         0.758328        0.001634               14  \n",
       "25           0.759421         0.758451        0.001655               12  \n",
       "26           0.758998         0.758581        0.001935               11  \n",
       "27           0.758672         0.758174        0.001498               15  \n",
       "28           0.759708         0.758808        0.001675                8  \n",
       "29           0.758864         0.758121        0.001901               16  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.relplot(data=result_df,\n",
    "\tkind='line',\n",
    "\tx='param_lgbmclassifier__num_leaves',\n",
    "\ty='mean_test_score',\n",
    "\tcol='param_lgbmclassifier__learning_rate'\n",
    "           )\n",
    "\n",
    "#g.set_titles('evolucion de scores por cantidad de hojas usadas {param_lgbmclassifier__objective}')\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'scaler':[StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
    "    'lgbmclassifier__learning_rate': [0.01, 0.05, 0.1], \n",
    "    #'lgbmclassifier__n_estimators': [30],\n",
    "    #'lgbmclassifier__num_leaves': [10, 50, 100, 150, 175 200, 225, 250, 275, 300], \n",
    "    'lgbmclassifier__num_iterations': [10, 50, 100, 150, 175, 200, 225, 250, 275, 300], \n",
    "    #'lgbmclassifier__boosting_type': ['gbdt'], \n",
    "    #'lgbmclassifier__max_depth': [10, 50, 100, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'lgbmclassifier__objective': ['regression'], \n",
    "    #'lgbmclassifier__seed': [500],\n",
    "    #'lgbmclassifier__colsample_bytree': [0.65, 0.75, 0.8], \n",
    "    #'lgbmclassifier__subsample': [0.7, 0.75], \n",
    "    #'lgbmclassifier__reg_alpha': [1, 2, 6],\n",
    "    #'lgbmclassifier__reg_lambda': [1, 2, 6]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lgbmclassifier',\n",
       "                                        LGBMClassifier(random_state=2021))]),\n",
       "             param_grid={'lgbmclassifier__learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'lgbmclassifier__num_iterations': [10, 50, 100, 150,\n",
       "                                                            175, 200, 225, 250,\n",
       "                                                            275, 300],\n",
       "                         'lgbmclassifier__objective': ['regression']})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train_values_subset, df_train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7724874424887088"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "in_sample_preds = gs.predict(train_values_subset)\n",
    "f1_score(df_train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgbmclassifier__learning_rate': 0.1, 'lgbmclassifier__num_iterations': 300, 'lgbmclassifier__objective': 'regression'}\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lgbmclassifier',\n",
      "                 LGBMClassifier(num_iterations=300, objective='regression',\n",
      "                                random_state=2021))])\n"
     ]
    }
   ],
   "source": [
    "# Access the best set of parameters\n",
    "best_params = gs.best_params_\n",
    "print(best_params)\n",
    "# Stores the optimum model in best_pipe\n",
    "best_pipe = gs.best_estimator_\n",
    "print(best_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_lgbmclassifier__learning_rate',\n",
      "       'param_lgbmclassifier__num_iterations',\n",
      "       'param_lgbmclassifier__objective', 'params', 'split0_test_score',\n",
      "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
      "       'split4_test_score', 'mean_test_score', 'std_test_score',\n",
      "       'rank_test_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(gs.cv_results_, orient='columns')\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lgbmclassifier__learning_rate</th>\n",
       "      <th>param_lgbmclassifier__num_iterations</th>\n",
       "      <th>param_lgbmclassifier__objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969260</td>\n",
       "      <td>0.127251</td>\n",
       "      <td>0.063157</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.568907</td>\n",
       "      <td>0.568918</td>\n",
       "      <td>0.568899</td>\n",
       "      <td>0.568918</td>\n",
       "      <td>0.568918</td>\n",
       "      <td>0.568912</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.409138</td>\n",
       "      <td>0.546992</td>\n",
       "      <td>0.205850</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.709330</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.711071</td>\n",
       "      <td>0.708423</td>\n",
       "      <td>0.708998</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.297767</td>\n",
       "      <td>0.336551</td>\n",
       "      <td>0.413836</td>\n",
       "      <td>0.054851</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.742369</td>\n",
       "      <td>0.738277</td>\n",
       "      <td>0.743573</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.439521</td>\n",
       "      <td>0.126924</td>\n",
       "      <td>0.523051</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.750465</td>\n",
       "      <td>0.747506</td>\n",
       "      <td>0.751362</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.749309</td>\n",
       "      <td>0.750239</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.393989</td>\n",
       "      <td>0.091693</td>\n",
       "      <td>0.700635</td>\n",
       "      <td>0.061888</td>\n",
       "      <td>0.01</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.749290</td>\n",
       "      <td>0.753166</td>\n",
       "      <td>0.753070</td>\n",
       "      <td>0.751132</td>\n",
       "      <td>0.751716</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.092843</td>\n",
       "      <td>0.586403</td>\n",
       "      <td>0.855928</td>\n",
       "      <td>0.132212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.752883</td>\n",
       "      <td>0.749444</td>\n",
       "      <td>0.753933</td>\n",
       "      <td>0.754355</td>\n",
       "      <td>0.752226</td>\n",
       "      <td>0.752568</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.786487</td>\n",
       "      <td>0.157257</td>\n",
       "      <td>0.966808</td>\n",
       "      <td>0.036856</td>\n",
       "      <td>0.01</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.753976</td>\n",
       "      <td>0.750691</td>\n",
       "      <td>0.754547</td>\n",
       "      <td>0.754375</td>\n",
       "      <td>0.752609</td>\n",
       "      <td>0.753240</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.987073</td>\n",
       "      <td>0.164216</td>\n",
       "      <td>1.108843</td>\n",
       "      <td>0.072989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.754149</td>\n",
       "      <td>0.750345</td>\n",
       "      <td>0.755084</td>\n",
       "      <td>0.754893</td>\n",
       "      <td>0.752763</td>\n",
       "      <td>0.753447</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.641147</td>\n",
       "      <td>0.628129</td>\n",
       "      <td>1.287547</td>\n",
       "      <td>0.078151</td>\n",
       "      <td>0.01</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.754590</td>\n",
       "      <td>0.750307</td>\n",
       "      <td>0.755276</td>\n",
       "      <td>0.755257</td>\n",
       "      <td>0.753051</td>\n",
       "      <td>0.753696</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.484905</td>\n",
       "      <td>0.075275</td>\n",
       "      <td>1.371046</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.01, 'lgbmc...</td>\n",
       "      <td>0.754936</td>\n",
       "      <td>0.750787</td>\n",
       "      <td>0.755372</td>\n",
       "      <td>0.755430</td>\n",
       "      <td>0.753703</td>\n",
       "      <td>0.754045</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.983512</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.052583</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.716256</td>\n",
       "      <td>0.710994</td>\n",
       "      <td>0.714198</td>\n",
       "      <td>0.715790</td>\n",
       "      <td>0.712932</td>\n",
       "      <td>0.714034</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.836934</td>\n",
       "      <td>0.162356</td>\n",
       "      <td>0.227888</td>\n",
       "      <td>0.022837</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.754341</td>\n",
       "      <td>0.750672</td>\n",
       "      <td>0.755027</td>\n",
       "      <td>0.754470</td>\n",
       "      <td>0.753031</td>\n",
       "      <td>0.753508</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.148136</td>\n",
       "      <td>0.118031</td>\n",
       "      <td>0.552986</td>\n",
       "      <td>0.035161</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.752245</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.755602</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.090431</td>\n",
       "      <td>0.262853</td>\n",
       "      <td>0.784862</td>\n",
       "      <td>0.083598</td>\n",
       "      <td>0.05</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>0.752437</td>\n",
       "      <td>0.757329</td>\n",
       "      <td>0.758365</td>\n",
       "      <td>0.756715</td>\n",
       "      <td>0.756409</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.762981</td>\n",
       "      <td>0.247005</td>\n",
       "      <td>0.886582</td>\n",
       "      <td>0.068020</td>\n",
       "      <td>0.05</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757334</td>\n",
       "      <td>0.753089</td>\n",
       "      <td>0.757368</td>\n",
       "      <td>0.758634</td>\n",
       "      <td>0.756734</td>\n",
       "      <td>0.756632</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.550567</td>\n",
       "      <td>0.120091</td>\n",
       "      <td>0.966880</td>\n",
       "      <td>0.056458</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757372</td>\n",
       "      <td>0.753338</td>\n",
       "      <td>0.757272</td>\n",
       "      <td>0.758634</td>\n",
       "      <td>0.756946</td>\n",
       "      <td>0.756712</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.156319</td>\n",
       "      <td>0.152091</td>\n",
       "      <td>1.030283</td>\n",
       "      <td>0.050237</td>\n",
       "      <td>0.05</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757257</td>\n",
       "      <td>0.753358</td>\n",
       "      <td>0.757157</td>\n",
       "      <td>0.758807</td>\n",
       "      <td>0.756888</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.913667</td>\n",
       "      <td>0.141515</td>\n",
       "      <td>1.220794</td>\n",
       "      <td>0.111125</td>\n",
       "      <td>0.05</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757756</td>\n",
       "      <td>0.753185</td>\n",
       "      <td>0.757310</td>\n",
       "      <td>0.759037</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756897</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.932935</td>\n",
       "      <td>0.446444</td>\n",
       "      <td>1.241428</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>0.05</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.757641</td>\n",
       "      <td>0.752916</td>\n",
       "      <td>0.757291</td>\n",
       "      <td>0.759305</td>\n",
       "      <td>0.757291</td>\n",
       "      <td>0.756889</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.209135</td>\n",
       "      <td>0.126825</td>\n",
       "      <td>1.301203</td>\n",
       "      <td>0.048887</td>\n",
       "      <td>0.05</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.05, 'lgbmc...</td>\n",
       "      <td>0.758178</td>\n",
       "      <td>0.753281</td>\n",
       "      <td>0.757329</td>\n",
       "      <td>0.759325</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.757062</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.978314</td>\n",
       "      <td>0.030949</td>\n",
       "      <td>0.082077</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.744115</td>\n",
       "      <td>0.740138</td>\n",
       "      <td>0.745510</td>\n",
       "      <td>0.747659</td>\n",
       "      <td>0.742882</td>\n",
       "      <td>0.744061</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.825118</td>\n",
       "      <td>0.160043</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>0.032836</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.756164</td>\n",
       "      <td>0.752398</td>\n",
       "      <td>0.756696</td>\n",
       "      <td>0.757464</td>\n",
       "      <td>0.756389</td>\n",
       "      <td>0.755822</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.566481</td>\n",
       "      <td>0.103439</td>\n",
       "      <td>0.510986</td>\n",
       "      <td>0.030961</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.757809</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.756954</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.216791</td>\n",
       "      <td>0.417372</td>\n",
       "      <td>0.677636</td>\n",
       "      <td>0.058395</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757679</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.758001</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>0.758058</td>\n",
       "      <td>0.757349</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.627093</td>\n",
       "      <td>0.116411</td>\n",
       "      <td>0.703089</td>\n",
       "      <td>0.057663</td>\n",
       "      <td>0.1</td>\n",
       "      <td>175</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757890</td>\n",
       "      <td>0.753799</td>\n",
       "      <td>0.758078</td>\n",
       "      <td>0.759612</td>\n",
       "      <td>0.758116</td>\n",
       "      <td>0.757499</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.164750</td>\n",
       "      <td>0.379282</td>\n",
       "      <td>0.763996</td>\n",
       "      <td>0.046773</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757737</td>\n",
       "      <td>0.754528</td>\n",
       "      <td>0.758308</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.758519</td>\n",
       "      <td>0.757733</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.046921</td>\n",
       "      <td>0.128760</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.1</td>\n",
       "      <td>225</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757890</td>\n",
       "      <td>0.754624</td>\n",
       "      <td>0.758212</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>0.758672</td>\n",
       "      <td>0.757806</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.746318</td>\n",
       "      <td>0.749881</td>\n",
       "      <td>0.941375</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.755046</td>\n",
       "      <td>0.758519</td>\n",
       "      <td>0.759785</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.757879</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.335144</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>1.047975</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>0.1</td>\n",
       "      <td>275</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.757967</td>\n",
       "      <td>0.755104</td>\n",
       "      <td>0.758903</td>\n",
       "      <td>0.759958</td>\n",
       "      <td>0.758500</td>\n",
       "      <td>0.758086</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.987100</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>1.142911</td>\n",
       "      <td>0.069708</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>regression</td>\n",
       "      <td>{'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...</td>\n",
       "      <td>0.758121</td>\n",
       "      <td>0.755065</td>\n",
       "      <td>0.758461</td>\n",
       "      <td>0.760553</td>\n",
       "      <td>0.758864</td>\n",
       "      <td>0.758213</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.969260      0.127251         0.063157        0.026841   \n",
       "1        3.409138      0.546992         0.205850        0.026445   \n",
       "2        5.297767      0.336551         0.413836        0.054851   \n",
       "3        7.439521      0.126924         0.523051        0.007067   \n",
       "4        8.393989      0.091693         0.700635        0.061888   \n",
       "5       10.092843      0.586403         0.855928        0.132212   \n",
       "6       10.786487      0.157257         0.966808        0.036856   \n",
       "7       11.987073      0.164216         1.108843        0.072989   \n",
       "8       13.641147      0.628129         1.287547        0.078151   \n",
       "9       14.484905      0.075275         1.371046        0.045187   \n",
       "10       0.983512      0.022066         0.052583        0.004180   \n",
       "11       2.836934      0.162356         0.227888        0.022837   \n",
       "12       5.148136      0.118031         0.552986        0.035161   \n",
       "13       7.090431      0.262853         0.784862        0.083598   \n",
       "14       7.762981      0.247005         0.886582        0.068020   \n",
       "15       8.550567      0.120091         0.966880        0.056458   \n",
       "16       9.156319      0.152091         1.030283        0.050237   \n",
       "17       9.913667      0.141515         1.220794        0.111125   \n",
       "18      10.932935      0.446444         1.241428        0.051919   \n",
       "19      11.209135      0.126825         1.301203        0.048887   \n",
       "20       0.978314      0.030949         0.082077        0.018076   \n",
       "21       2.825118      0.160043         0.280891        0.032836   \n",
       "22       4.566481      0.103439         0.510986        0.030961   \n",
       "23       6.216791      0.417372         0.677636        0.058395   \n",
       "24       6.627093      0.116411         0.703089        0.057663   \n",
       "25       7.164750      0.379282         0.763996        0.046773   \n",
       "26       8.046921      0.128760         0.883462        0.058987   \n",
       "27       8.746318      0.749881         0.941375        0.022442   \n",
       "28       9.335144      0.078141         1.047975        0.082524   \n",
       "29       9.987100      0.112481         1.142911        0.069708   \n",
       "\n",
       "   param_lgbmclassifier__learning_rate param_lgbmclassifier__num_iterations  \\\n",
       "0                                 0.01                                   10   \n",
       "1                                 0.01                                   50   \n",
       "2                                 0.01                                  100   \n",
       "3                                 0.01                                  150   \n",
       "4                                 0.01                                  175   \n",
       "5                                 0.01                                  200   \n",
       "6                                 0.01                                  225   \n",
       "7                                 0.01                                  250   \n",
       "8                                 0.01                                  275   \n",
       "9                                 0.01                                  300   \n",
       "10                                0.05                                   10   \n",
       "11                                0.05                                   50   \n",
       "12                                0.05                                  100   \n",
       "13                                0.05                                  150   \n",
       "14                                0.05                                  175   \n",
       "15                                0.05                                  200   \n",
       "16                                0.05                                  225   \n",
       "17                                0.05                                  250   \n",
       "18                                0.05                                  275   \n",
       "19                                0.05                                  300   \n",
       "20                                 0.1                                   10   \n",
       "21                                 0.1                                   50   \n",
       "22                                 0.1                                  100   \n",
       "23                                 0.1                                  150   \n",
       "24                                 0.1                                  175   \n",
       "25                                 0.1                                  200   \n",
       "26                                 0.1                                  225   \n",
       "27                                 0.1                                  250   \n",
       "28                                 0.1                                  275   \n",
       "29                                 0.1                                  300   \n",
       "\n",
       "   param_lgbmclassifier__objective  \\\n",
       "0                       regression   \n",
       "1                       regression   \n",
       "2                       regression   \n",
       "3                       regression   \n",
       "4                       regression   \n",
       "5                       regression   \n",
       "6                       regression   \n",
       "7                       regression   \n",
       "8                       regression   \n",
       "9                       regression   \n",
       "10                      regression   \n",
       "11                      regression   \n",
       "12                      regression   \n",
       "13                      regression   \n",
       "14                      regression   \n",
       "15                      regression   \n",
       "16                      regression   \n",
       "17                      regression   \n",
       "18                      regression   \n",
       "19                      regression   \n",
       "20                      regression   \n",
       "21                      regression   \n",
       "22                      regression   \n",
       "23                      regression   \n",
       "24                      regression   \n",
       "25                      regression   \n",
       "26                      regression   \n",
       "27                      regression   \n",
       "28                      regression   \n",
       "29                      regression   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.568907   \n",
       "1   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.709330   \n",
       "2   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.742369   \n",
       "3   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.750465   \n",
       "4   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.751923   \n",
       "5   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.752883   \n",
       "6   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.753976   \n",
       "7   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.754149   \n",
       "8   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.754590   \n",
       "9   {'lgbmclassifier__learning_rate': 0.01, 'lgbmc...           0.754936   \n",
       "10  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.716256   \n",
       "11  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.754341   \n",
       "12  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.755818   \n",
       "13  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757200   \n",
       "14  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757334   \n",
       "15  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757372   \n",
       "16  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757257   \n",
       "17  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757756   \n",
       "18  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.757641   \n",
       "19  {'lgbmclassifier__learning_rate': 0.05, 'lgbmc...           0.758178   \n",
       "20  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.744115   \n",
       "21  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.756164   \n",
       "22  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757142   \n",
       "23  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757679   \n",
       "24  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757890   \n",
       "25  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757737   \n",
       "26  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757890   \n",
       "27  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758025   \n",
       "28  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.757967   \n",
       "29  {'lgbmclassifier__learning_rate': 0.1, 'lgbmcl...           0.758121   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.568918           0.568899           0.568918   \n",
       "1            0.707176           0.711071           0.708423   \n",
       "2            0.738277           0.743573           0.744302   \n",
       "3            0.747506           0.751362           0.752552   \n",
       "4            0.749290           0.753166           0.753070   \n",
       "5            0.749444           0.753933           0.754355   \n",
       "6            0.750691           0.754547           0.754375   \n",
       "7            0.750345           0.755084           0.754893   \n",
       "8            0.750307           0.755276           0.755257   \n",
       "9            0.750787           0.755372           0.755430   \n",
       "10           0.710994           0.714198           0.715790   \n",
       "11           0.750672           0.755027           0.754470   \n",
       "12           0.752245           0.756581           0.757521   \n",
       "13           0.752437           0.757329           0.758365   \n",
       "14           0.753089           0.757368           0.758634   \n",
       "15           0.753338           0.757272           0.758634   \n",
       "16           0.753358           0.757157           0.758807   \n",
       "17           0.753185           0.757310           0.759037   \n",
       "18           0.752916           0.757291           0.759305   \n",
       "19           0.753281           0.757329           0.759325   \n",
       "20           0.740138           0.745510           0.747659   \n",
       "21           0.752398           0.756696           0.757464   \n",
       "22           0.753837           0.757809           0.758787   \n",
       "23           0.753492           0.758001           0.759517   \n",
       "24           0.753799           0.758078           0.759612   \n",
       "25           0.754528           0.758308           0.759574   \n",
       "26           0.754624           0.758212           0.759632   \n",
       "27           0.755046           0.758519           0.759785   \n",
       "28           0.755104           0.758903           0.759958   \n",
       "29           0.755065           0.758461           0.760553   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.568918         0.568912        0.000008               30  \n",
       "1            0.708998         0.709000        0.001269               29  \n",
       "2            0.741117         0.741927        0.002122               27  \n",
       "3            0.749309         0.750239        0.001732               25  \n",
       "4            0.751132         0.751716        0.001429               24  \n",
       "5            0.752226         0.752568        0.001734               23  \n",
       "6            0.752609         0.753240        0.001445               22  \n",
       "7            0.752763         0.753447        0.001752               21  \n",
       "8            0.753051         0.753696        0.001878               19  \n",
       "9            0.753703         0.754045        0.001744               18  \n",
       "10           0.712932         0.714034        0.001924               28  \n",
       "11           0.753031         0.753508        0.001562               20  \n",
       "12           0.755602         0.755554        0.001786               17  \n",
       "13           0.756715         0.756409        0.002058               15  \n",
       "14           0.756734         0.756632        0.001876               14  \n",
       "15           0.756946         0.756712        0.001782               12  \n",
       "16           0.756888         0.756693        0.001798               13  \n",
       "17           0.757195         0.756897        0.001968               10  \n",
       "18           0.757291         0.756889        0.002122               11  \n",
       "19           0.757195         0.757062        0.002037                8  \n",
       "20           0.742882         0.744061        0.002523               26  \n",
       "21           0.756389         0.755822        0.001767               16  \n",
       "22           0.757195         0.756954        0.001667                9  \n",
       "23           0.758058         0.757349        0.002030                7  \n",
       "24           0.758116         0.757499        0.001951                6  \n",
       "25           0.758519         0.757733        0.001709                5  \n",
       "26           0.758672         0.757806        0.001696                4  \n",
       "27           0.758020         0.757879        0.001556                3  \n",
       "28           0.758500         0.758086        0.001628                2  \n",
       "29           0.758864         0.758213        0.001782                1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.relplot(data=result_df,\n",
    "\tkind='line',\n",
    "\tx='param_lgbmclassifier__num_iterations',\n",
    "\ty='mean_test_score',\n",
    "\tcol='param_lgbmclassifier__learning_rate'\n",
    "           )\n",
    "\n",
    "#g.set_titles('evolucion de scores por cantidad de hojas usadas {param_lgbmclassifier__objective}')\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
