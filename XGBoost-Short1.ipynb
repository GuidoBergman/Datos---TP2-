{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ca8df8",
   "metadata": {},
   "source": [
    "Aclaracion: para no hacer el archivo largo y repetitivo se fueorn pisando las cosas anteriores a medida que se encontraba algun hiperparametro. El orden en el que se fue buscando cada hiperparametro se encuentra en el informe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c01547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bayesian_optimization in /home/guido/.local/lib/python3.6/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/guido/.local/lib/python3.6/site-packages (from bayesian_optimization) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/guido/.local/lib/python3.6/site-packages (from bayesian_optimization) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/guido/.local/lib/python3.6/site-packages (from bayesian_optimization) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/guido/.local/lib/python3.6/site-packages (from scikit-learn>=0.18.0->bayesian_optimization) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/guido/.local/lib/python3.6/site-packages (from scikit-learn>=0.18.0->bayesian_optimization) (2.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/guido/.local/lib/python3.6/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in /home/guido/.local/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/guido/.local/lib/python3.6/site-packages (from xgboost) (1.5.4)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install bayesian_optimization\n",
    "! pip3 install xgboost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import SequentialDomainReductionTransformer\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.util import load_logs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('train_values_short1.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv('train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b1a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(resultado):\n",
    "    return resultado['target']\n",
    "\n",
    "def mostrar(resultados, min=0):\n",
    "    \n",
    "    a_borrar = []\n",
    "    for resultado in resultados:\n",
    "        if(resultado['target']<min):\n",
    "            a_borrar.append(resultado)\n",
    "    resultados_importantes = [a for a in resultados if a not in a_borrar]\n",
    "    \n",
    "    resultados_importantes.sort(reverse=True, key=target)\n",
    "    \n",
    "    for resultado in resultados_importantes:\n",
    "        print(\"target: \" , resultado['target'])\n",
    "        for key,value in resultado['params'].items():\n",
    "            print(\"\\t\\t\", key, ':', value)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb197fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_a_optimizar(n_estimators):\n",
    "    x = train_values\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y=train_labels.values.ravel())\n",
    "    xgb = XGBClassifier( objective = \"multi:softmax\", use_label_encoder=False, seed=30,\n",
    "                         max_depth=9,\n",
    "                         min_child_weight=6,\n",
    "                         gamma=0.2554138025988315,\n",
    "                        colsample_bytree : 0.7773754946860542,\n",
    "                        subsample : 0.9030471581301206,\n",
    "                         learning_rate =0.1, \n",
    "                         n_estimators=round(n_estimators), \n",
    "                         )\n",
    "                       \n",
    "    return cross_val_score(xgb, x, y, scoring='f1_micro', cv=15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be275d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "limites = {\"n_estimators\":(240,500) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad1d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=funcion_a_optimizar,\n",
    "    random_state=130,\n",
    "    verbose=5,\n",
    "    pbounds=limites,\n",
    "    bounds_transformer=SequentialDomainReductionTransformer(),\n",
    ")\n",
    "\n",
    "#load_logs(optimizer, \"logs/XGBoost/short1_colsample_y_subsample.json\")\n",
    "logger = JSONLogger(path=\"./con_feature_engiering_colsample_y_subsample.json\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f00f9ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:26:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=5,\n",
    "    n_iter=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09dc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.probe({\"n_estimators\":250 }, lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.probe({\"n_estimators\":500 }, lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305f0079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  0.7609794364028688\n",
      "\t\t colsample_bytree : 0.7773754946860542\n",
      "\t\t subsample : 0.9030471581301206\n",
      "\n",
      "target:  0.7609755949815245\n",
      "\t\t colsample_bytree : 0.7516279046947797\n",
      "\t\t subsample : 0.9041745677290469\n",
      "\n",
      "target:  0.7608835054117528\n",
      "\t\t colsample_bytree : 0.793979582481109\n",
      "\t\t subsample : 0.9379215375319068\n",
      "\n",
      "target:  0.7606264015504329\n",
      "\t\t colsample_bytree : 0.7469412902446044\n",
      "\t\t subsample : 0.9605639199302624\n",
      "\n",
      "target:  0.760434541187873\n",
      "\t\t colsample_bytree : 0.9993754357285763\n",
      "\t\t subsample : 0.8854617864361789\n",
      "\n",
      "target:  0.7603616326628214\n",
      "\t\t colsample_bytree : 0.8\n",
      "\t\t subsample : 0.8\n",
      "\n",
      "target:  0.7602963971151808\n",
      "\t\t colsample_bytree : 0.870021465386449\n",
      "\t\t subsample : 0.9952381867757054\n",
      "\n",
      "target:  0.7602388388149969\n",
      "\t\t colsample_bytree : 0.7417011879574652\n",
      "\t\t subsample : 0.9717460034548407\n",
      "\n",
      "target:  0.7602081371873175\n",
      "\t\t colsample_bytree : 0.7773961457821672\n",
      "\t\t subsample : 0.5629057093051787\n",
      "\n",
      "target:  0.7601620931386464\n",
      "\t\t colsample_bytree : 0.6899225170721807\n",
      "\t\t subsample : 0.5632248257216661\n",
      "\n",
      "target:  0.7600776712455396\n",
      "\t\t colsample_bytree : 0.5708151345383703\n",
      "\t\t subsample : 0.655772180563795\n",
      "\n",
      "target:  0.7599472035368462\n",
      "\t\t colsample_bytree : 1.0\n",
      "\t\t subsample : 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mostrar(optimizer.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40672c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'xgbclassifier__n_estimators': [255, 260, 265, 270, 271, 272, 273, 274, 275]}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=15)\n",
    "gs.fit(train_values, train_labels)\n",
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
